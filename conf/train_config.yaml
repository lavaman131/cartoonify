pretrained_model_name_or_path: null
revision: null
tokenizer_name: null
instance_data_dir: null
class_data_dir: null
instance_prompt: null
class_prompt: null
with_prior_preservation: false
prior_loss_weight: 1.0
num_class_images: 100
output_dir: text-inversion-model
seed: 42
resolution: 512
center_crop: false
train_text_encoder: false
train_batch_size: 4
sample_batch_size: 4
num_train_epochs: 1
max_train_steps: null
checkpointing_steps: 500
checkpoints_total_limit: null
resume_from_checkpoint: null
gradient_accumulation_steps: 1
gradient_checkpointing: false
learning_rate: 0.000005
scale_lr: false
lr_scheduler: constant
lr_warmup_steps: 500
lr_num_cycles: 1
lr_power: 1.0
use_8bit_adam: false
dataloader_num_workers: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
push_to_hub: false
hub_token: null
hub_model_id: null
logging_dir: logs
allow_tf32: false
report_to: wandb
validation_prompt: null
num_validation_images: 4
validation_steps: 100
mixed_precision: null
prior_generation_precision: null
local_rank: -1
enable_xformers_memory_efficient_attention: false
set_grads_to_none: false
offset_noise: false
snr_gamma: null
pre_compute_text_embeddings: false
tokenizer_max_length: null
text_encoder_use_attention_mask: false
skip_save_text_encoder: false
validation_images: null
class_labels_conditioning: null
validation_scheduler: DPMSolverMultistepScheduler
